{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-Time Face Detection using OpenCV in Python: A Beginner's Guide\n",
    "\n",
    "This tutorial will walk you through creating a real-time face detection program using OpenCV in Python. We'll capture video from a webcam (or a file) and use a pre-trained Haar Cascade model to detect faces in each frame.\n",
    "\n",
    "Here's a [link](https://github.com/samietex/Deep_Learning_Tutorial/blob/main/Face%20Detection-Recognition/video.py) to the source code.\n",
    "\n",
    "### Prerequisites\n",
    "As stated in the [Face Detection of Images Notebook](https://github.com/samietex/Deep_Learning_Tutorial/blob/main/Face%20Detection-Recognition/face_detection_image.ipynb)\n",
    "\n",
    "### Step-by-Step Tutorial\n",
    "\n",
    "**Import OpenCV Library:** \n",
    "We start by importing the OpenCV library in your Python script. OpenCV (Open Source Computer Vision Library) is used for computer vision and machine learning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This line imports the OpenCV library, which is a comprehensive library used for real-time computer vision.\n",
    "\n",
    "**Load the Haar Cascade Classifier:** \n",
    "We will use a pre-trained Haar Cascade model for face detection. This model is stored in an XML file.\n",
    "\n",
    "Ensure the `'haarcascade_frontalface_default.xml'` file is in the same directory as your script or provide the full path to the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a cascade classifier object face_cascade that will be used for detecting faces. The classifier is loaded with the `'haarcascade_frontalface_default.xml'` file, which contains pre-trained data necessary for face detection.\n",
    "\n",
    "**Setting Up Video Capture:**\n",
    "We set up a video capture object. `cv2.VideoCapture(0)` initializes it to capture video from your webcam. The parameter `0` refers to the default webcam. You can replace `0` with a file path to use a video file instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# cap = cv2.VideoCapture('filename.mp4') -- In case you want to use a video file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sets up the video capture object. `cv2.VideoCapture(0)` initializes the capture object to use the webcam. The parameter `0` denotes the default webcam. Alternatively, you can capture from a video file by commenting the webcam line and uncommenting `cv2.VideoCapture('filename.mp4')`, where `'filename.mp4'` is your video file.\n",
    "\n",
    "**Capturing and Processing Video Frames:**\n",
    "We enter a loop where we continuously capture frames from the video source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    _, img = cap.read()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an infinite loop that continuously captures frames from the webcam/video file. `cap.read()` returns a boolean and the captured frame. The boolean (here, represented by `_`) is ignored, and the frame is stored in `img`.\n",
    "\n",
    "**Convert Frame to Grayscale:**\n",
    "Convert each captured frame to grayscale. Face detection is more efficient in a single color channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each captured frame is converted to grayscale. This is because the face detection process is faster and more efficient in a single color channel.\n",
    "\n",
    "**Detect Faces in the Frame:**\n",
    "We use the `detectMultiScale` method on the grayscale image to detect faces. The parameters control the image scale and the number of neighbors each rectangle should have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = face_cascade.detectMultiScale(gray, 1.1, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method `detectMultiScale` is used on the grayscale image to detect faces. The parameters `1.1` and `4` function as in the previous script, controlling the scale factor and the minNeighbors, respectively.\n",
    "\n",
    "**Drawing Rectangles Around Detected Faces:**\n",
    "Draw a rectangle around each detected face in the frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each detected face, this loop draws a blue rectangle (with BGR color `(255, 0, 0)` and thickness `2`) around it on the original frame.\n",
    "\n",
    "**Display the Processed Frame:**\n",
    "Display the frame with rectangles drawn around detected faces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('img', img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The processed frame, now with rectangles drawn around any detected faces, is displayed in a window titled 'img'.\n",
    "\n",
    "**Exit Condition:**\n",
    "The loop can be stopped by pressing the 'ESC' key (key code 27)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = cv2.waitKey(30) & 0xff\n",
    "if k==27:\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code waits for 30 milliseconds for a key event and breaks the loop if the escape key (key code 27) is pressed. It ensures that the script can be safely exited.\n",
    "\n",
    "**Releasing Video Capture Object:**\n",
    "Release the video capture object after breaking out of the loop. This step is crucial for freeing the resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the loop is exited (usually by pressing the escape key), this line releases the video capture object. It's important for releasing the webcam or closing the file, freeing the resources used.\n",
    "\n",
    "This tutorial is an introduction to real-time video processing using OpenCV in Python. Experiment with different parameters and video sources to explore further."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
